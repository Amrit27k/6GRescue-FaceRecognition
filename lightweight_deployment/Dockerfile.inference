# Dockerfile for Jetson Inference Application
FROM nvcr.io/nvidia/l4t-base:r32.7.1

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    python3-dev \
    python3-opencv \
    libopencv-dev \
    pkg-config \
    wget \
    curl \
    gstreamer1.0-tools \
    gstreamer1.0-plugins-base \
    gstreamer1.0-plugins-good \
    gstreamer1.0-plugins-bad \
    gstreamer1.0-plugins-ugly \
    gstreamer1.0-libav \
    libgstreamer1.0-dev \
    libgstreamer-plugins-base1.0-dev \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements and install Python dependencies
COPY requirements_jetson.txt .
RUN pip3 install --no-cache-dir -r requirements_jetson.txt

# Copy application files
COPY jetson_inference.py .

# Create output directory
RUN mkdir -p output

# Expose web server port
EXPOSE 8080

# Set environment variables
ENV PYTHONPATH=/app
ENV MODEL_SERVICE_URL=http://face-recognition-model-service
ENV PYTHONUNBUFFERED=1

# Run the inference application in web mode
CMD ["python3", "jetson_inference.py", "--web", "--no-display"]
